{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fichier d'entrainement et de visulation - FFN Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The project involves scraping data from the French Swimming Federation website and using it to train a machine learning model. The goal is to provide advanced statistics and predictions on a swimmer's performance. This Jupyter Notebook serves as both a sandbox and a logbook, documenting the thought process and implementation of the machine learning model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To collect data from the FFN website, we utilized the Beautiful Soup library in Python to extract information from the HTML code. In addition, we also obtained an XML file from the website that we had to parse. We used the lxml library to read the XML file and extract the necessary data.\n",
    "\n",
    "Once we obtained the data, we organized it into a structured format and stored it in an external database. We used the sqlite3 library in Python to create and manipulate the database. The data was divided into tables based on the type of information, such as swimmer profiles, competition results, and rankings.\n",
    "\n",
    "We created functions to automate the process of scraping and storing the data, allowing us to easily update the database with new information. We also performed data validation to ensure that the extracted data was accurate and complete.\n",
    "\n",
    "Overall, the data scraping process required a combination of tools and techniques to extract and organize the data in a way that was suitable for machine learning analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data for Data analysis and Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV format is a simple and widely used file format for storing and exchanging tabular data. It can be easily read and manipulated in a variety of tools and platforms, including machine learning libraries such as scikit-learn and TensorFlow. CSV files also have a relatively small file size compared to other file formats, making them suitable for large datasets.\n",
    "\n",
    "In addition, CSV files are highly customizable and can be easily modified to fit different use cases. For example, we were able to modify the column headers and data types to suit the requirements of our specific machine learning pipeline.\n",
    "\n",
    "Overall, we chose to export the data in CSV format due to its compatibility with machine learning libraries, ease of use, and flexibility."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
